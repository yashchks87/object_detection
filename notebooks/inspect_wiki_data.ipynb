{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch, torchvision\n",
    "import os\n",
    "import cv2, PIL\n",
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "from resize_boxes import resize_values\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import multiprocessing as mp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_gpus = False\n",
    "if torch.cuda.is_available():\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        multiple_gpus = True\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_csv = pd.read_csv('./wiki.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>img_path</th>\n",
       "      <th>dob</th>\n",
       "      <th>photo_taken_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "      <th>face_location</th>\n",
       "      <th>face_score</th>\n",
       "      <th>updated_paths</th>\n",
       "      <th>valid_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17/10000217_1981-05-05_2009.jpg</td>\n",
       "      <td>1981-05-05</td>\n",
       "      <td>2009</td>\n",
       "      <td>M</td>\n",
       "      <td>Sami Jauhojärvi</td>\n",
       "      <td>111.29109473290997, 111.29109473290997, 252.66...</td>\n",
       "      <td>4.300962</td>\n",
       "      <td>../../IMDB_WIKI/wiki/17/10000217_1981-05-05_20...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>48/10000548_1925-04-04_1964.jpg</td>\n",
       "      <td>1925-04-04</td>\n",
       "      <td>1964</td>\n",
       "      <td>M</td>\n",
       "      <td>Dettmar Cramer</td>\n",
       "      <td>252.48330229530742, 126.68165114765371, 354.53...</td>\n",
       "      <td>2.645639</td>\n",
       "      <td>../../IMDB_WIKI/wiki/48/10000548_1925-04-04_19...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12/100012_1948-07-03_2008.jpg</td>\n",
       "      <td>1948-07-03</td>\n",
       "      <td>2008</td>\n",
       "      <td>M</td>\n",
       "      <td>Marc Okrand</td>\n",
       "      <td>113.52, 169.83999999999997, 366.08, 422.4</td>\n",
       "      <td>4.329329</td>\n",
       "      <td>../../IMDB_WIKI/wiki/12/100012_1948-07-03_2008...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>65/10001965_1930-05-23_1961.jpg</td>\n",
       "      <td>1930-05-23</td>\n",
       "      <td>1961</td>\n",
       "      <td>M</td>\n",
       "      <td>Aleksandar Matanović</td>\n",
       "      <td>1, 1, 634, 440</td>\n",
       "      <td>-inf</td>\n",
       "      <td>../../IMDB_WIKI/wiki/65/10001965_1930-05-23_19...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>16/10002116_1971-05-31_2012.jpg</td>\n",
       "      <td>1971-05-31</td>\n",
       "      <td>2012</td>\n",
       "      <td>F</td>\n",
       "      <td>Diana Damrau</td>\n",
       "      <td>171.61031405173117, 75.57451239763239, 266.766...</td>\n",
       "      <td>3.408442</td>\n",
       "      <td>../../IMDB_WIKI/wiki/16/10002116_1971-05-31_20...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                         img_path         dob  photo_taken_year  \\\n",
       "0           0  17/10000217_1981-05-05_2009.jpg  1981-05-05              2009   \n",
       "1           1  48/10000548_1925-04-04_1964.jpg  1925-04-04              1964   \n",
       "2           2    12/100012_1948-07-03_2008.jpg  1948-07-03              2008   \n",
       "3           3  65/10001965_1930-05-23_1961.jpg  1930-05-23              1961   \n",
       "4           4  16/10002116_1971-05-31_2012.jpg  1971-05-31              2012   \n",
       "\n",
       "  gender                  name  \\\n",
       "0      M       Sami Jauhojärvi   \n",
       "1      M        Dettmar Cramer   \n",
       "2      M           Marc Okrand   \n",
       "3      M  Aleksandar Matanović   \n",
       "4      F          Diana Damrau   \n",
       "\n",
       "                                       face_location  face_score  \\\n",
       "0  111.29109473290997, 111.29109473290997, 252.66...    4.300962   \n",
       "1  252.48330229530742, 126.68165114765371, 354.53...    2.645639   \n",
       "2          113.52, 169.83999999999997, 366.08, 422.4    4.329329   \n",
       "3                                     1, 1, 634, 440        -inf   \n",
       "4  171.61031405173117, 75.57451239763239, 266.766...    3.408442   \n",
       "\n",
       "                                       updated_paths  valid_images  \n",
       "0  ../../IMDB_WIKI/wiki/17/10000217_1981-05-05_20...           1.0  \n",
       "1  ../../IMDB_WIKI/wiki/48/10000548_1925-04-04_19...           1.0  \n",
       "2  ../../IMDB_WIKI/wiki/12/100012_1948-07-03_2008...           1.0  \n",
       "3  ../../IMDB_WIKI/wiki/65/10001965_1930-05-23_19...           1.0  \n",
       "4  ../../IMDB_WIKI/wiki/16/10002116_1971-05-31_20...           1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please load issue image paths and remove them for getting used.\n",
    "with open('./issue_paths.pkl', 'rb') as handle:\n",
    "    issues = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_csv = wiki_csv[~wiki_csv['updated_paths'].isin(issues)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_single_channel(img_path):\n",
    "    img = torchvision.io.read_file(img_path)\n",
    "    img = torchvision.io.decode_jpeg(img)\n",
    "    return (img_path, img.shape)\n",
    "def drop_single_channel_imgs(csv_file):\n",
    "    paths = csv_file['updated_paths'].values.tolist()\n",
    "    issues = []\n",
    "    with mp.Pool(6) as p:\n",
    "        detected = list(p.map(detect_single_channel, paths))\n",
    "    for x in detected:\n",
    "        if x[1][0] == 1:\n",
    "            issues.append(x[0])\n",
    "    return csv_file[~csv_file['updated_paths'].isin(issues)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 11 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 839 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 549 extraneous bytes before marker 0xd9\n"
     ]
    }
   ],
   "source": [
    "wiki_csv = drop_single_channel_imgs(wiki_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_first_values(boxes):\n",
    "    location_values = []\n",
    "    for x in boxes:\n",
    "        temp = x.split(',')\n",
    "        current_data = []\n",
    "        for x in temp:\n",
    "            current_data.append(float(x))\n",
    "        location_values.append(current_data)\n",
    "    return location_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datasets(csv_file, test_size=0.01):\n",
    "    train, test = train_test_split(csv_file, test_size=test_size, random_state=42)\n",
    "    train, val = train_test_split(train, test_size=test_size, random_state=42)\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, img_paths, boxes, target_size):\n",
    "        super().__init__()\n",
    "        self.img_paths = img_paths\n",
    "        self.boxes = fix_first_values(boxes)\n",
    "        self.target_size = target_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = torchvision.io.read_file(self.img_paths[idx])\n",
    "        img = torchvision.io.decode_jpeg(img)\n",
    "        box = torch.Tensor(resize_values(self.boxes[idx], img.shape, self.target_size, return_old_box=False, is_torch=True)).float()\n",
    "        img = torchvision.transforms.functional.resize(img, (self.target_size[0], self.target_size[1]))\n",
    "        img = img.float()\n",
    "        return img, box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = FaceDataset(train['updated_paths'].values.tolist(), train['face_location'].values.tolist(), (512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.__getitem__(5)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_get_model():\n",
    "    model = torchvision.models.resnet50()\n",
    "    model.fc = nn.Linear(2048, 4)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(inputs, targets):\n",
    "    x0 = torch.sum(torch.abs(targets[:, 0] - inputs[:, 0]) / inputs.shape[0])\n",
    "    y0 = torch.sum(torch.abs(targets[:, 1] - inputs[:, 1]) / inputs.shape[0])\n",
    "    x1 = torch.sum(torch.abs(targets[:, 2] - inputs[:, 2]) / inputs.shape[0])\n",
    "    y1 = torch.sum(torch.abs(targets[:, 3] - inputs[:, 3]) / inputs.shape[0])\n",
    "    return x0 + y0 + x1 + y1\n",
    "    # loss = nn.L1Loss()\n",
    "    # output = loss(inputs, targets)\n",
    "    # return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, train_dataset, val_dataset, epochs):\n",
    "    datasets = {\n",
    "        'train': train_dataset,\n",
    "        'val' : val_dataset\n",
    "    }\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    if next(model.parameters()).is_cuda == False:\n",
    "        if multiple_gpus == True:\n",
    "            model = nn.DataParallel(model)\n",
    "        model = model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        train_epoch_x0_loss = 0.0\n",
    "        val_epoch_x0_loss = 0.0\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            if phase == 'val':\n",
    "                model.eval()\n",
    "            running_x0_loss = 0.0\n",
    "            with tqdm(datasets[phase], unit='batch') as tepoch:\n",
    "                for img, label in tepoch:\n",
    "                    tepoch.set_description(f'Epoch: {epoch}')\n",
    "                    img = img.to(device)\n",
    "                    label = label.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(img)\n",
    "                        loss = loss_fn(outputs, label)\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                    running_x0_loss += loss.item()\n",
    "                    tepoch.set_postfix(loss = loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = split_datasets(wiki_csv, 0.01)\n",
    "train_dataset = FaceDataset(train['updated_paths'].values.tolist(), train['face_location'].values.tolist(), (256, 256))\n",
    "train_loader = DataLoader(train_dataset, 16, True, prefetch_factor=2)\n",
    "val_dataset = FaceDataset(val['updated_paths'].values.tolist(), val['face_location'].values.tolist(), (256, 256))\n",
    "val_loader = DataLoader(val_dataset, 16, True, prefetch_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0:   4%|▍         | 114/2846 [01:06<26:39,  1.71batch/s, loss=203]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/paperspace/Documents/object_detection/notebooks/inspect_wiki_data.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B64.62.255.37/home/paperspace/Documents/object_detection/notebooks/inspect_wiki_data.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_fn(create_and_get_model(), train_loader, val_loader, \u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32m/home/paperspace/Documents/object_detection/notebooks/inspect_wiki_data.ipynb Cell 18\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B64.62.255.37/home/paperspace/Documents/object_detection/notebooks/inspect_wiki_data.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m         loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B64.62.255.37/home/paperspace/Documents/object_detection/notebooks/inspect_wiki_data.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m         optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B64.62.255.37/home/paperspace/Documents/object_detection/notebooks/inspect_wiki_data.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m running_x0_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B64.62.255.37/home/paperspace/Documents/object_detection/notebooks/inspect_wiki_data.ipynb#Y101sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m tepoch\u001b[39m.\u001b[39mset_postfix(loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_fn(create_and_get_model(), train_loader, val_loader, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env",
   "language": "python",
   "name": "base_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
